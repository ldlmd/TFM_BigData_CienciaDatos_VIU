{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Máster en Big Data y Data Science\n",
    "\n",
    "### TFM\n",
    "\n",
    "#### MODELOS DE APRENDIZAJE NO SUPERVISADO : CLUSTERING\n",
    "\n",
    "---\n",
    "\n",
    "En esta libreta se generan los modelos de clusterización sobre el dataset final del escenario para su posterior evaluación y análisis. Se utilizará como herramienta de soporte a mlflow para el registro completo de la experimentación. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:fg:1: no job control in this shell.\n"
     ]
    }
   ],
   "source": [
    "!%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:fg:1: no job control in this shell.\n"
     ]
    }
   ],
   "source": [
    "!%pip install kmodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:fg:1: no job control in this shell.\n"
     ]
    }
   ],
   "source": [
    "!%pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Se importa mlflow para registro de la experimentación \n",
    "import mlflow\n",
    "\n",
    "# Se importan los métodos a utilizar para clusterizar\n",
    "from kmodes.kmodes import KModes\n",
    "\n",
    "# Se importan las métricas a utilizar para evaluar el proceso\n",
    "from sklearn.metrics import davies_bouldin_score, homogeneity_score, completeness_score, v_measure_score\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "##### Lectura del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tipo_producto</th>\n",
       "      <th>Condición</th>\n",
       "      <th>Localidad</th>\n",
       "      <th>Marca</th>\n",
       "      <th>precio</th>\n",
       "      <th>precio_envio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>auriculares</td>\n",
       "      <td>totalmente nuevo</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>otra</td>\n",
       "      <td>barato</td>\n",
       "      <td>desconocido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>auriculares</td>\n",
       "      <td>totalmente nuevo</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>lenovo</td>\n",
       "      <td>barato</td>\n",
       "      <td>desconocido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>auriculares</td>\n",
       "      <td>totalmente nuevo</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>muy barato</td>\n",
       "      <td>gratis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>auriculares</td>\n",
       "      <td>totalmente nuevo</td>\n",
       "      <td>china</td>\n",
       "      <td>jbl</td>\n",
       "      <td>barato</td>\n",
       "      <td>gratis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>auriculares</td>\n",
       "      <td>totalmente nuevo</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>otra</td>\n",
       "      <td>muy barato</td>\n",
       "      <td>gratis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Tipo_producto         Condición    Localidad   Marca  \\\n",
       "0           1   auriculares  totalmente nuevo  Desconocido    otra   \n",
       "1           2   auriculares  totalmente nuevo  Desconocido  lenovo   \n",
       "2           3   auriculares  totalmente nuevo  Desconocido  xiaomi   \n",
       "3           4   auriculares  totalmente nuevo        china     jbl   \n",
       "4           6   auriculares  totalmente nuevo  Desconocido    otra   \n",
       "\n",
       "       precio precio_envio  \n",
       "0      barato  desconocido  \n",
       "1      barato  desconocido  \n",
       "2  muy barato       gratis  \n",
       "3      barato       gratis  \n",
       "4  muy barato       gratis  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/lorenadlmd/Desktop/Master BIGDATA/BIGDATA/TFM/python_VisualStudio/modelado/datos/dataset_transformado_final.csv', sep=\",\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rs/9vrff58j4zdcj52xz4pt7w3r0000gn/T/ipykernel_38472/1064296010.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda s: s.lower() if type(s) == str else s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tipo_producto</th>\n",
       "      <th>Condición</th>\n",
       "      <th>Localidad</th>\n",
       "      <th>Marca</th>\n",
       "      <th>precio</th>\n",
       "      <th>precio_envio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>auriculares</td>\n",
       "      <td>totalmente nuevo</td>\n",
       "      <td>desconocido</td>\n",
       "      <td>otra</td>\n",
       "      <td>barato</td>\n",
       "      <td>desconocido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>auriculares</td>\n",
       "      <td>totalmente nuevo</td>\n",
       "      <td>desconocido</td>\n",
       "      <td>lenovo</td>\n",
       "      <td>barato</td>\n",
       "      <td>desconocido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>auriculares</td>\n",
       "      <td>totalmente nuevo</td>\n",
       "      <td>desconocido</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>muy barato</td>\n",
       "      <td>gratis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>auriculares</td>\n",
       "      <td>totalmente nuevo</td>\n",
       "      <td>china</td>\n",
       "      <td>jbl</td>\n",
       "      <td>barato</td>\n",
       "      <td>gratis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>auriculares</td>\n",
       "      <td>totalmente nuevo</td>\n",
       "      <td>desconocido</td>\n",
       "      <td>otra</td>\n",
       "      <td>muy barato</td>\n",
       "      <td>gratis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Tipo_producto         Condición    Localidad   Marca  \\\n",
       "0           1   auriculares  totalmente nuevo  desconocido    otra   \n",
       "1           2   auriculares  totalmente nuevo  desconocido  lenovo   \n",
       "2           3   auriculares  totalmente nuevo  desconocido  xiaomi   \n",
       "3           4   auriculares  totalmente nuevo        china     jbl   \n",
       "4           6   auriculares  totalmente nuevo  desconocido    otra   \n",
       "\n",
       "       precio precio_envio  \n",
       "0      barato  desconocido  \n",
       "1      barato  desconocido  \n",
       "2  muy barato       gratis  \n",
       "3      barato       gratis  \n",
       "4  muy barato       gratis  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "##### Configuración de la experimentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentacon con kmodes para distintas configuraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se genera el experimento en mlflow\n",
    "exp_name = 'Experimentación clustering1: kmodes'\n",
    "exp_id = mlflow.create_experiment(name=exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimentos registrados en MLflow.\n"
     ]
    }
   ],
   "source": [
    "# Definir los parámetros a evaluar\n",
    "k_values = [2, 3]\n",
    "init_methods = ['Huang', 'Cao']\n",
    "\n",
    "for k in k_values:\n",
    "    for init in init_methods:\n",
    "        with mlflow.start_run():\n",
    "            # Ajustar el modelo K-Modes\n",
    "            km = KModes(n_clusters=k, init=init, n_init=5)\n",
    "            labels = km.fit_predict(df)\n",
    "\n",
    "            # Calcular métricas (ejemplo: Davies-Bouldin Index)\n",
    "\n",
    "            # Necesidad de convertir a numericas las variables para el calculo de DBS: one hot encoding\n",
    "            encoder = OneHotEncoder(sparse_output=False)\n",
    "            X_encoded = encoder.fit_transform(df)\n",
    "\n",
    "            #Calcular el Davies-Bouldin-Score\n",
    "            davies_bouldin = davies_bouldin_score(X_encoded, labels)\n",
    "\n",
    "            # Calcular las distancias entre todos los puntos utilizando distancia Hamming\n",
    "            distancias = pairwise_distances( X_encoded, metric='hamming')\n",
    "\n",
    "            # Calcular el Silhouette Score\n",
    "            silhouette_avg = silhouette_score(distancias, labels, metric=\"precomputed\")\n",
    "\n",
    "            # Registrar parámetros y métricas en MLflow\n",
    "            mlflow.log_param(\"k\", k)\n",
    "            mlflow.log_param(\"init_method\", init)\n",
    "            mlflow.log_metric(\"davies_bouldin_score\", davies_bouldin )\n",
    "            mlflow.log_metric(\"silhouette_score\", silhouette_avg )\n",
    "\n",
    "            # registrar el modelo si lo deseas\n",
    "            #mlflow.log_artifact(\"path/to/your/model\")  # Si guardas el modelo\n",
    "\n",
    "print(\"Experimentos registrados en MLflow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-07 14:03:38 +0100] [43966] [INFO] Starting gunicorn 23.0.0\n",
      "[2024-11-07 14:03:38 +0100] [43966] [INFO] Listening at: http://127.0.0.1:5000 (43966)\n",
      "[2024-11-07 14:03:38 +0100] [43966] [INFO] Using worker: sync\n",
      "[2024-11-07 14:03:38 +0100] [43967] [INFO] Booting worker with pid: 43967\n",
      "[2024-11-07 14:03:38 +0100] [43968] [INFO] Booting worker with pid: 43968\n",
      "[2024-11-07 14:03:39 +0100] [43969] [INFO] Booting worker with pid: 43969\n",
      "[2024-11-07 14:03:39 +0100] [43970] [INFO] Booting worker with pid: 43970\n",
      "^C\n",
      "[2024-11-07 14:04:05 +0100] [43966] [INFO] Handling signal: int\n",
      "[2024-11-07 14:04:05 +0100] [43970] [INFO] Worker exiting (pid: 43970)\n",
      "[2024-11-07 14:04:05 +0100] [43969] [INFO] Worker exiting (pid: 43969)\n",
      "[2024-11-07 14:04:05 +0100] [43967] [INFO] Worker exiting (pid: 43967)\n",
      "[2024-11-07 14:04:05 +0100] [43968] [INFO] Worker exiting (pid: 43968)\n"
     ]
    }
   ],
   "source": [
    "# Visualizar resultados en mlflow\n",
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.7772839007585652\n",
      "Silhouette Score promedio para clustering: 0.1944943204195812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/07 14:13:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "# Por cada método se debe registrar la ejecución\n",
    "with mlflow.start_run(experiment_id=exp_id, run_name=\"Kmodes - K=2 init: Huang\"):\n",
    "    # Selección y configuración de la técnica\n",
    "    modelo_clusters = KModes(n_clusters=2, init='Huang', n_init=5)\n",
    "    \n",
    "    trained_model = modelo_clusters.fit(df)\n",
    "    cluster_labels = trained_model.labels_\n",
    "\n",
    "    # Calcular métricas (ejemplo: Davies-Bouldin Index)\n",
    "\n",
    "    # Necesidad de convertir a numericas las variables para el calculo de DBS: one hot encoding\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    X_encoded = encoder.fit_transform(df)\n",
    "\n",
    "     #Calcular el Davies-Bouldin-Score\n",
    "    davies_bouldin = davies_bouldin_score(X_encoded, labels)\n",
    "    print(f\"Davies-Bouldin Index: {davies_bouldin}\")\n",
    "    # Calcular las distancias entre todos los puntos utilizando distancia Hamming\n",
    "    distancias = pairwise_distances( X_encoded, metric='hamming')\n",
    "\n",
    "    # Calcular el Silhouette Score\n",
    "    silhouette_avg = silhouette_score(distancias, labels, metric=\"precomputed\")\n",
    "    print(f\"Silhouette Score promedio para clustering: {silhouette_avg}\")\n",
    "    \n",
    "    # Registrar parámetros y métricas en MLflow\n",
    "    mlflow.log_param(\"k\", 2)\n",
    "    mlflow.log_param(\"init_method\", 'Huang')\n",
    "    mlflow.log_metric(\"davies_bouldin_score\", davies_bouldin )\n",
    "    mlflow.log_metric(\"silhouette_score\", silhouette_avg )\n",
    "    \n",
    "\n",
    "    # Se guarda el modelo generado\n",
    "    mlflow.sklearn.log_model(trained_model, \"Kmeans_K2-Huang\")\n",
    "\n",
    "    # Se finaliza el registro\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para contabilizar los elementos por cluster se utilizan las labels generadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "0    5911\n",
       "1    3622\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se preserva el conjunto de datos original para evitar problemas\n",
    "df_kmeans_k2_huang = df.copy()\n",
    "# Se agregan las labels generadas\n",
    "df_kmeans_k2_huang['cluster'] = cluster_labels\n",
    "df_kmeans_k2_huang['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se prueban el resto de configuraciones de K-Modes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k=2 init ='Cao'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 2.7772839007585652\n",
      "Silhouette Score promedio para clustering: 0.1944943204195812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/07 14:17:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "# Por cada método se debe registrar la ejecución\n",
    "with mlflow.start_run(experiment_id=exp_id, run_name=\"Kmodes - K=2 init: Cao\"):\n",
    "    # Selección y configuración de la técnica\n",
    "    modelo_clusters = KModes(n_clusters=2, init='Cao', n_init=5)\n",
    "    \n",
    "    trained_model = modelo_clusters.fit(df)\n",
    "    cluster_labels = trained_model.labels_\n",
    "\n",
    "    # Calcular métricas (ejemplo: Davies-Bouldin Index)\n",
    "\n",
    "    # Necesidad de convertir a numericas las variables para el calculo de DBS: one hot encoding\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    X_encoded = encoder.fit_transform(df)\n",
    "\n",
    "     #Calcular el Davies-Bouldin-Score\n",
    "    davies_bouldin = davies_bouldin_score(X_encoded, labels)\n",
    "    print(f\"Davies-Bouldin Index: {davies_bouldin}\")\n",
    "    # Calcular las distancias entre todos los puntos utilizando distancia Hamming\n",
    "    distancias = pairwise_distances( X_encoded, metric='hamming')\n",
    "\n",
    "    # Calcular el Silhouette Score\n",
    "    silhouette_avg = silhouette_score(distancias, labels, metric=\"precomputed\")\n",
    "    print(f\"Silhouette Score promedio para clustering: {silhouette_avg}\")\n",
    "\n",
    "    # Registrar parámetros y métricas en MLflow\n",
    "    mlflow.log_param(\"k\", 2)\n",
    "    mlflow.log_param(\"init_method\", 'Cao')\n",
    "    mlflow.log_metric(\"davies_bouldin_score\", davies_bouldin)\n",
    "    mlflow.log_metric(\"silhouette_score\", silhouette_avg )\n",
    "\n",
    "    # Se guarda el modelo generado\n",
    "    mlflow.sklearn.log_model(trained_model, \"Kmeans_K2-Cao\")\n",
    "\n",
    "    # Se finaliza el registro\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "0    6346\n",
       "1    3187\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se preserva el conjunto de datos original para evitar problemas\n",
    "df_kmeans_k2_cao = df.copy()\n",
    "# Se agregan las labels generadas\n",
    "df_kmeans_k2_cao['cluster'] = cluster_labels\n",
    "df_kmeans_k2_cao['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k=3 init= 'Huang'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 1 1]\n",
      "Davies-Bouldin Index: 2.7772839007585652\n",
      "Silhouette Score promedio para clustering: 0.1944943204195812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/07 14:22:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(experiment_id=exp_id, run_name=\"Kmodes - K=3 init: Huang\"):\n",
    "    # Selección y configuración de la técnica\n",
    "    modelo_clusters = KModes(n_clusters=3, init='Huang', n_init=5)\n",
    "    \n",
    "    trained_model = modelo_clusters.fit(df)\n",
    "    cluster_labels = trained_model.labels_\n",
    "    print(cluster_labels)\n",
    "    # Calcular métricas (ejemplo: Davies-Bouldin Index)\n",
    "\n",
    "    # Necesidad de convertir a numericas las variables para el calculo de DBS: one hot encoding\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    X_encoded = encoder.fit_transform(df)\n",
    "\n",
    "     #Calcular el Davies-Bouldin-Score\n",
    "    davies_bouldin = davies_bouldin_score(X_encoded, labels)\n",
    "    print(f\"Davies-Bouldin Index: {davies_bouldin}\")\n",
    "\n",
    "    # Calcular las distancias entre todos los puntos utilizando distancia Hamming\n",
    "    distancias = pairwise_distances( X_encoded, metric='hamming')\n",
    "\n",
    "    # Calcular el Silhouette Score\n",
    "    silhouette_avg = silhouette_score(distancias, labels, metric=\"precomputed\")\n",
    "    print(f\"Silhouette Score promedio para clustering: {silhouette_avg}\")\n",
    "    \n",
    "\n",
    "    # Registrar parámetros y métricas en MLflow\n",
    "    mlflow.log_param(\"k\", 3)\n",
    "    mlflow.log_param(\"init_method\", 'Huang')\n",
    "    mlflow.log_metric(\"davies_bouldin_score\", davies_bouldin)\n",
    "    mlflow.log_metric(\"silhouette_score\", silhouette_avg )\n",
    "\n",
    "    # Se guarda el modelo generado\n",
    "    mlflow.sklearn.log_model(trained_model, \"Kmeans_K3-Huang\")\n",
    "\n",
    "    # Se finaliza el registro\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "0    4964\n",
       "1    2850\n",
       "2    1719\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se preserva el conjunto de datos original para evitar problemas\n",
    "df_kmeans_k3_huang = df.copy()\n",
    "# Se agregan las labels generadas\n",
    "df_kmeans_k3_huang['cluster'] = cluster_labels\n",
    "df_kmeans_k3_huang['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k=3 init=Cao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 0 1 1]\n",
      "Davies-Bouldin Index: 3.5677670748626906\n",
      "Silhouette Score promedio para clustering: 0.13158094307661888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/07 15:30:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "# Por cada método se debe registrar la ejecución\n",
    "with mlflow.start_run(experiment_id=exp_id, run_name=\"Kmodes - K=3 init: Huang\"):\n",
    "    # Selección y configuración de la técnica\n",
    "    modelo_clusters = KModes(n_clusters=3, init='Huang', n_init=5)\n",
    "    \n",
    "    trained_model = modelo_clusters.fit(df)\n",
    "    cluster_labels = trained_model.labels_\n",
    "    print(cluster_labels)\n",
    "\n",
    "    # Calcular métricas (ejemplo: Davies-Bouldin Index)\n",
    "\n",
    "    # Necesidad de convertir a numericas las variables para el calculo de DBS: one hot encoding\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    X_encoded = encoder.fit_transform(df)\n",
    "\n",
    "    #Calcular el Davies-Bouldin-Score\n",
    "    davies_bouldin = davies_bouldin_score(X_encoded, cluster_labels)\n",
    "    print(f\"Davies-Bouldin Index: {davies_bouldin}\")\n",
    "   \n",
    "   # Calcular las distancias entre todos los puntos utilizando distancia Hamming\n",
    "    distancias = pairwise_distances( X_encoded, metric='hamming')\n",
    "\n",
    "    # Calcular el Silhouette Score\n",
    "    silhouette_avg = silhouette_score(distancias, cluster_labels, metric=\"precomputed\")\n",
    "    print(f\"Silhouette Score promedio para clustering: {silhouette_avg}\")\n",
    "\n",
    "\n",
    "    # Registrar parámetros y métricas en MLflow\n",
    "    mlflow.log_param(\"k\", 3)\n",
    "    mlflow.log_param(\"init_method\", 'Cao')\n",
    "    mlflow.log_metric(\"davies_bouldin_score\", davies_bouldin)\n",
    "    mlflow.log_metric(\"silhouette_score\", silhouette_avg)\n",
    "\n",
    "    # Se guarda el modelo generado\n",
    "    mlflow.sklearn.log_model(trained_model, \"Kmeans_K3-Cao\")\n",
    "\n",
    "    # Se finaliza el registro\n",
    "    mlflow.end_run()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:fg:1: no job control in this shell.\n",
      "zsh:fg:1: no job control in this shell.\n"
     ]
    }
   ],
   "source": [
    "!%pip install scipy\n",
    "!%pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "0    4956\n",
       "1    2870\n",
       "2    1707\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se preserva el conjunto de datos original para evitar problemas\n",
    "df_kmeans_k3_cao = df.copy()\n",
    "# Se agregan las labels generadas\n",
    "df_kmeans_k3_cao['cluster'] = cluster_labels\n",
    "df_kmeans_k3_cao['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-07 14:26:20 +0100] [49269] [INFO] Starting gunicorn 23.0.0\n",
      "[2024-11-07 14:26:20 +0100] [49269] [INFO] Listening at: http://127.0.0.1:5000 (49269)\n",
      "[2024-11-07 14:26:20 +0100] [49269] [INFO] Using worker: sync\n",
      "[2024-11-07 14:26:20 +0100] [49270] [INFO] Booting worker with pid: 49270\n",
      "[2024-11-07 14:26:21 +0100] [49271] [INFO] Booting worker with pid: 49271\n",
      "[2024-11-07 14:26:21 +0100] [49272] [INFO] Booting worker with pid: 49272\n",
      "[2024-11-07 14:26:21 +0100] [49273] [INFO] Booting worker with pid: 49273\n",
      "^C\n",
      "[2024-11-07 14:59:40 +0100] [49269] [INFO] Handling signal: int\n",
      "[2024-11-07 14:59:40 +0100] [49273] [INFO] Worker exiting (pid: 49273)\n",
      "[2024-11-07 14:59:40 +0100] [49270] [INFO] Worker exiting (pid: 49270)\n",
      "[2024-11-07 14:59:40 +0100] [49271] [INFO] Worker exiting (pid: 49271)\n",
      "[2024-11-07 14:59:40 +0100] [49272] [INFO] Worker exiting (pid: 49272)\n"
     ]
    }
   ],
   "source": [
    "# Visualizar resultados en mlflow\n",
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:fg:1: no job control in this shell.\n"
     ]
    }
   ],
   "source": [
    "!%pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------ EJEMPLOS Y PRUEBAS------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pasa a probar otro método (clustering jerárquico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/08 21:36:20 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    }
   ],
   "source": [
    "# Por cada método se debe registrar la ejecución\n",
    "with mlflow.start_run(experiment_id=exp_id, run_name=\"AGClustering - K=3\"):\n",
    "    # Selección y configuración de la técnica\n",
    "    modelo_clusters = AgglomerativeClustering(n_clusters=3)\n",
    "    \n",
    "    trained_model = modelo_clusters.fit(df)\n",
    "    cluster_labels = trained_model.labels_\n",
    "\n",
    "    # Se realizar el cálculo de las métricas seleccionadas\n",
    "    score_s = silhouette_score(df, cluster_labels)\n",
    "    score_db = davies_bouldin_score(df, cluster_labels)\n",
    "    score_ch = calinski_harabasz_score(df, cluster_labels)\n",
    "\n",
    "    # Se registra el parámetro K\n",
    "    mlflow.log_param('Valor K', 3)\n",
    "\n",
    "    # Se registran las métricas de evaluación\n",
    "    mlflow.log_metric('silhouette_score', score_s)\n",
    "    mlflow.log_metric('davies_bouldin_score', score_db)\n",
    "    mlflow.log_metric('calinski_harabasz_score', score_ch)\n",
    "\n",
    "    # Se guarda el modelo generado\n",
    "    mlflow.sklearn.log_model(trained_model, \"AGC_K3\")\n",
    "\n",
    "    # Se finaliza el registro\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para contabilizar los elementos por cluster se utilizan las labels generadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "1    4697\n",
       "2    3817\n",
       "0     371\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se preserva el conjunto de datos original para evitar problemas\n",
    "df_agc_k3 = df.copy()\n",
    "# Se agregan las labels generadas\n",
    "df_agc_k3['cluster'] = cluster_labels\n",
    "df_agc_k3['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se prueba un método que no tiene parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por cada método se debe registrar la ejecución\n",
    "with mlflow.start_run(experiment_id=exp_id, run_name=\"MeanShift\"):\n",
    "    # Selección y configuración de la técnica\n",
    "    modelo_clusters = MeanShift()\n",
    "    \n",
    "    trained_model = modelo_clusters.fit(df)\n",
    "    cluster_labels = trained_model.labels_\n",
    "\n",
    "    # Se realizar el cálculo de las métricas seleccionadas\n",
    "    score_s = silhouette_score(df, cluster_labels)\n",
    "    score_db = davies_bouldin_score(df, cluster_labels)\n",
    "    score_ch = calinski_harabasz_score(df, cluster_labels)\n",
    "\n",
    "    # No hay parámetros por registrar\n",
    "\n",
    "    # Se registran las métricas de evaluación\n",
    "    mlflow.log_metric('silhouette_score', score_s)\n",
    "    mlflow.log_metric('davies_bouldin_score', score_db)\n",
    "    mlflow.log_metric('calinski_harabasz_score', score_ch)\n",
    "\n",
    "    # Se guarda el modelo generado\n",
    "    mlflow.sklearn.log_model(trained_model, \"MS\")\n",
    "\n",
    "    # Se finaliza el registro\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para contabilizar los elementos por cluster se utilizan las labels generadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "0    8519\n",
       "1     306\n",
       "2      39\n",
       "3      11\n",
       "4       6\n",
       "5       3\n",
       "6       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se preserva el conjunto de datos original para evitar problemas\n",
    "df_ms = df.copy()\n",
    "# Se agregan las labels generadas\n",
    "df_ms['cluster'] = cluster_labels\n",
    "df_ms['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Prueba Nro. 2\n",
    "\n",
    "- Kmeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por cada método se debe registrar la ejecución\n",
    "with mlflow.start_run(experiment_id=exp_id, run_name=\"Kmeans - K=3\"):\n",
    "    # Selección y configuración de la técnica\n",
    "    modelo_clusters = KMeans(n_clusters=3)\n",
    "    \n",
    "    trained_model = modelo_clusters.fit(df)\n",
    "    cluster_labels = trained_model.labels_\n",
    "\n",
    "    # Se realizar el cálculo de las métricas seleccionadas\n",
    "    score_s = silhouette_score(df, cluster_labels)\n",
    "    score_db = davies_bouldin_score(df, cluster_labels)\n",
    "    score_ch = calinski_harabasz_score(df, cluster_labels)\n",
    "\n",
    "    # Se registra el parámetro K\n",
    "    mlflow.log_param('Valor K', 3)\n",
    "\n",
    "    # Se registran las métricas de evaluación\n",
    "    mlflow.log_metric('silhouette_score', score_s)\n",
    "    mlflow.log_metric('davies_bouldin_score', score_db)\n",
    "    mlflow.log_metric('calinski_harabasz_score', score_ch)\n",
    "\n",
    "    # Se guarda el modelo generado\n",
    "    mlflow.sklearn.log_model(trained_model, \"Kmeans_K3\")\n",
    "\n",
    "    # Se finaliza el registro\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "0    4703\n",
       "1    3876\n",
       "2     306\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se preserva el conjunto de datos original para evitar problemas\n",
    "df_kmeans_k3 = df.copy()\n",
    "# Se agregan las labels generadas\n",
    "df_kmeans_k3['cluster'] = cluster_labels\n",
    "df_kmeans_k3['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kmeans_k3.to_csv(\"../../../data/final/resultados_kmeans_k3.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clustering Jerárquico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/08 21:40:54 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    }
   ],
   "source": [
    "# Por cada método se debe registrar la ejecución\n",
    "with mlflow.start_run(experiment_id=exp_id, run_name=\"AGClustering - K=2\"):\n",
    "    # Selección y configuración de la técnica\n",
    "    modelo_clusters = AgglomerativeClustering(n_clusters=2)\n",
    "    \n",
    "    trained_model = modelo_clusters.fit(df)\n",
    "    cluster_labels = trained_model.labels_\n",
    "\n",
    "    # Se realizar el cálculo de las métricas seleccionadas\n",
    "    score_s = silhouette_score(df, cluster_labels)\n",
    "    score_db = davies_bouldin_score(df, cluster_labels)\n",
    "    score_ch = calinski_harabasz_score(df, cluster_labels)\n",
    "\n",
    "    # Se registra el parámetro K\n",
    "    mlflow.log_param('Valor K', 2)\n",
    "\n",
    "    # Se registran las métricas de evaluación\n",
    "    mlflow.log_metric('silhouette_score', score_s)\n",
    "    mlflow.log_metric('davies_bouldin_score', score_db)\n",
    "    mlflow.log_metric('calinski_harabasz_score', score_ch)\n",
    "\n",
    "    # Se guarda el modelo generado\n",
    "    mlflow.sklearn.log_model(trained_model, \"AGC_K2\")\n",
    "\n",
    "    # Se finaliza el registro\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "0    8514\n",
       "1     371\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se preserva el conjunto de datos original para evitar problemas\n",
    "df_agc_k2 = df.copy()\n",
    "# Se agregan las labels generadas\n",
    "df_agc_k2['cluster'] = cluster_labels\n",
    "df_agc_k2['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agc_k2.to_csv(\"../../../data/final/resultados_df_agc_k2.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Experimentación #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment 'mlruns'. Detailed error Yaml file '/Users/lorenadlmd/Desktop/Master BIGDATA/BIGDATA/Metodologia de proyectos/P1/13MBID-Proyectos/notebooks/modelado/Clusterizacion_reglas/mlruns/mlruns/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lorenadlmd/Desktop/Master BIGDATA/BIGDATA/Metodologia de proyectos/P1/13MBID-Proyectos/.env/lib/python3.12/site-packages/mlflow/store/tracking/file_store.py\", line 302, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenadlmd/Desktop/Master BIGDATA/BIGDATA/Metodologia de proyectos/P1/13MBID-Proyectos/.env/lib/python3.12/site-packages/mlflow/store/tracking/file_store.py\", line 395, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenadlmd/Desktop/Master BIGDATA/BIGDATA/Metodologia de proyectos/P1/13MBID-Proyectos/.env/lib/python3.12/site-packages/mlflow/store/tracking/file_store.py\", line 1320, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenadlmd/Desktop/Master BIGDATA/BIGDATA/Metodologia de proyectos/P1/13MBID-Proyectos/.env/lib/python3.12/site-packages/mlflow/store/tracking/file_store.py\", line 1313, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lorenadlmd/Desktop/Master BIGDATA/BIGDATA/Metodologia de proyectos/P1/13MBID-Proyectos/.env/lib/python3.12/site-packages/mlflow/utils/file_utils.py\", line 310, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/Users/lorenadlmd/Desktop/Master BIGDATA/BIGDATA/Metodologia de proyectos/P1/13MBID-Proyectos/notebooks/modelado/Clusterizacion_reglas/mlruns/mlruns/meta.yaml' does not exist.\n"
     ]
    }
   ],
   "source": [
    "# Se genera el experimento en mlflow\n",
    "exp_name_2 = 'Experimentación clustering_ap2 #2'\n",
    "exp_id_2 = mlflow.create_experiment(name=exp_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/08 21:41:20 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    }
   ],
   "source": [
    "# Por cada método se debe registrar la ejecución\n",
    "with mlflow.start_run(experiment_id=exp_id_2, run_name=\"AGClustering - K=3\"):\n",
    "    # Selección y configuración de la técnica\n",
    "    modelo_clusters = AgglomerativeClustering(n_clusters=3)\n",
    "    \n",
    "    trained_model = modelo_clusters.fit(df)\n",
    "    cluster_labels = trained_model.labels_\n",
    "\n",
    "    # Se realizar el cálculo de las métricas seleccionadas\n",
    "    score_s = silhouette_score(df, cluster_labels)\n",
    "    score_db = davies_bouldin_score(df, cluster_labels)\n",
    "    score_ch = calinski_harabasz_score(df, cluster_labels)\n",
    "\n",
    "    # Se registra el parámetro K\n",
    "    mlflow.log_param('Valor K', 3)\n",
    "\n",
    "    # Se registran las métricas de evaluación\n",
    "    mlflow.log_metric('silhouette_score', score_s)\n",
    "    mlflow.log_metric('davies_bouldin_score', score_db)\n",
    "    mlflow.log_metric('calinski_harabasz_score', score_ch)\n",
    "\n",
    "    # Se guarda el modelo generado\n",
    "    mlflow.sklearn.log_model(trained_model, \"AGC_K3\")\n",
    "\n",
    "    # Se finaliza el registro\n",
    "    mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huemul",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
